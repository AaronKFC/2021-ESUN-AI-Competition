{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224\n",
    "model_path = './models/efficientnet-b3_epoch100.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "model_test = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "num_ftrs = model_test._fc.in_features\n",
    "\n",
    "model_test._fc  = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_test.to(device)\n",
    "\n",
    "model_test.load_state_dict(torch.load(model_path))\n",
    "model_test.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model(model, input_image_path):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with Image.open(input_image_path) as input_image:\n",
    "            resized_image = data_transforms['val'](input_image).unsqueeze(0).to(device)\n",
    "            label = input_image_path.split('_')[-1].split('.')[0]\n",
    "            \n",
    "            output = model(resized_image)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            \n",
    "        model.train(mode=was_training)\n",
    "    \n",
    "    return class_names[pred[0]], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "words = ['2530_田.jpg', '4531_佳.jpg', '62947_科.jpg', '9997_王.jpg', '54240_允.jpg']\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    start = time.time()\n",
    "    pred, label = inference_model(model_test, os.path.join('./data/clean/', word))\n",
    "    print(f'Image {i + 1}\\nPredict: {pred}, Label: {label}, Time elapsed: {time.time() - start}\\n')\n",
    "    img = mpimg.imread(os.path.join('./data/clean', word))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print(f'Inference time of one image: {time_elapsed / len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = './data/val/isnull'\n",
    "val_words_file = []\n",
    "\n",
    "for root, dirs, files in os.walk(val_wordset_dir, topdown=True):\n",
    "    for name in files:\n",
    "        val_words_file.append(name)\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for i, word in enumerate(val_words):\n",
    "    pred, label = inference_model(model_test, os.path.join('./data/clean/', word))\n",
    "    preds.append(pred)\n",
    "    labels.append('isnull')\n",
    "\n",
    "print(f'The accuracy of isnull is {accuracy_score(preds, labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = './data/val'\n",
    "val_words = ['仙', '圖', '迅', '鑽', '勁', '班', '央', '衣', '買', '首', '匠', '厚']\n",
    "val_words_file = []\n",
    "\n",
    "for val_word in val_words:\n",
    "    for root, dirs, files in os.walk(os.path.join(val_dir, val_word), topdown=True):\n",
    "        for name in files:\n",
    "            val_words_file.append(name)\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for i, word in enumerate(val_words_file):\n",
    "    pred, label = inference_model(model_test, os.path.join('./data/clean/', word))\n",
    "    preds.append(pred)\n",
    "    labels.append(label)\n",
    "    \n",
    "print(f'The accuracy of little data images is {accuracy_score(preds, labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
